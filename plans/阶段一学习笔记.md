# 阶段一：入门与基础 - 学习笔记

## 任务1.1：环境准备

### 已完成的工作
1. **检查GPU环境**：
   - NVIDIA GeForce RTX 3060 (12GB显存)
   - CUDA版本：13.0（驱动），12.4（PyTorch）
   - PyTorch 2.6.0+cu124 已安装

2. **创建虚拟环境**：
   - 使用uv创建Python 3.12虚拟环境
   - 命令：`uv venv --python=3.12`

3. **安装依赖**：
   - 正在运行：`uv pip install -e .`
   - 观察到正在下载大量CUDA相关包（torch、nvidia-cublas-cu12、nvidia-cudnn-cu12等）
   - 总包数：77个，包括：
     - torch (858.1MiB)
     - nvidia-cublas-cu12 (566.8MiB)
     - nvidia-cudnn-cu12 (674.0MiB)
     - sgl-kernel (510.8MiB)
     - nvidia-nccl-cu12 (307.4MiB)

### 遇到的问题
- 安装过程较慢，因为需要下载多个GB大小的CUDA包
- 网络连接稳定，但下载速度有限

### 安装完成确认
- **总包数**: 77个
- **下载时间**: 约7分钟
- **安装时间**: 684毫秒
- **关键包**:
  - torch==2.9.1 (858.1MiB)
  - nvidia-cublas-cu12==12.8.4.1 (566.8MiB)
  - nvidia-cudnn-cu12==9.10.2.21 (674.0MiB)
  - sgl-kernel==0.3.21 (510.8MiB)
  - nvidia-nccl-cu12==2.27.5 (307.4MiB)
  - flashinfer-python==0.5.3
  - transformers==4.57.3
  - minisgl==0.1.0 (从本地安装)

### 学习收获
1. **mini-sGLang的依赖特点**：
   - 重度依赖NVIDIA CUDA生态
   - 包含自定义内核（sgl-kernel）
   - 使用TVM-FFI进行JIT编译
   - 支持FlashAttention和FlashInfer

2. **项目结构初步了解**：
   - 主入口：`python/minisgl/__main__.py`
   - 启动逻辑：`python/minisgl/server/launch.py`
   - API服务器：`python/minisgl/server/api_server.py`
   - 核心数据结构：`python/minisgl/core.py`

3. **多进程架构**：
   - 使用`multiprocessing`模块
   - 设置`spawn`启动方法
   - 包含多个组件进程：
     - Scheduler Workers（每个GPU一个）
     - Tokenizer Workers
     - Detokenizer Worker

### 代码分析笔记

#### launch.py 关键逻辑
```python
def launch_server(run_shell: bool = False) -> None:
    # 1. 解析命令行参数
    server_args, run_shell = parse_args(sys.argv[1:], run_shell)

    # 2. 启动子进程
    def start_subprocess() -> None:
        mp.set_start_method("spawn", force=True)

        # 为每个GPU启动一个scheduler
        for i in range(world_size):
            mp.Process(target=_run_scheduler, ...).start()

        # 启动detokenizer
        mp.Process(target=tokenize_worker, ...).start()

        # 启动tokenizers
        for i in range(num_tokenizers):
            mp.Process(target=tokenize_worker, ...).start()

    # 3. 运行API服务器
    run_api_server(server_args, start_subprocess, run_shell=run_shell)
```

#### 核心数据结构（初步）
- `SamplingParams`: 采样参数（温度、top_k、top_p等）
- `Req`: 请求对象，包含输入ID、缓存信息、采样参数等
- 关键属性：
  - `device_len`: 当前设备上的token数量
  - `max_device_len`: 最大token数量
  - `remain_len`: 剩余生成token数量
  - `extend_len`: 需要扩展的token数量

### 重要发现
- 用户提供了本地模型缓存路径：`/home/kason/.cache/modelscope/hub/models/Qwen/Qwen3-0.6B`
- 该路径包含完整的模型文件（1.5GB的safetensors文件）
- 可以使用本地路径避免模型下载

### 遇到的问题
**GLIBCXX版本不匹配错误（两个后端都有问题）**：

1. **FlashInfer后端错误**：
```
version `GLIBCXX_3.4.32' not found (required by ...flashinfer...so)
```

2. **FlashAttention后端错误**：
```
version `GLIBCXX_3.4.31' not found (required by ...tvm-ffi...so)
```

**原因分析**：
1. TVM-FFI和FlashInfer库在JIT编译时使用了较新的编译器
2. 生成的.so文件需要GLIBCXX_3.4.31/3.4.32
3. Anaconda的libstdc++.so.6版本为6.0.29，较旧，缺少这些符号
4. 系统libstdc++.so.6.0.33有这些符号，但程序加载了Anaconda的库
5. 根本原因：Anaconda环境中的libstdc++版本滞后于系统版本

**版本对比**：
- 系统libstdc++：6.0.33（支持GLIBCXX_3.4.33）
- Anaconda libstdc++：6.0.29（只支持到GLIBCXX_3.4.30？）

**解决方案分析**：

### 方案1: 设置LD_LIBRARY_PATH（最快捷）
```bash
export LD_LIBRARY_PATH="/usr/lib/x86_64-linux-gnu:$LD_LIBRARY_PATH"
source .venv/bin/activate
python -m minisgl --model-path "/home/kason/.cache/modelscope/hub/models/Qwen/Qwen3-0.6B" \
  --max-running-requests 2 --port 1919 --attention-backend fa
```

**优点**：快速，不需要安装或编译
**缺点**：可能不完全稳定，需要每次设置环境变量

### 方案2: 更新Anaconda的libstdcxx-ng
```bash
conda update libstdcxx-ng
# 或者
conda install -c conda-forge libstdcxx-ng=12
```

**优点**：永久解决Anaconda环境的问题
**缺点**：可能需要下载更新，可能影响其他Anaconda环境

### 方案3: 使用系统Python创建新虚拟环境
```bash
/usr/bin/python3 -m venv .venv-system
source .venv-system/bin/activate
uv pip install -e .
```

**优点**：使用系统较新的libstdc++，隔离性好
**缺点**：需要重新安装依赖

### 方案4: 使用Docker（最可靠）
```bash
docker build -t minisgl .
docker run --gpus all -p 1919:1919 minisgl --model Qwen/Qwen3-0.6B --host 0.0.0.0
```

**优点**：完全隔离，使用正确的库版本
**缺点**：需要Docker环境，首次构建需要时间

### 方案5: 从源码重新编译相关库
重新编译TVM-FFI和FlashInfer，使用与当前环境兼容的编译器。

**当前状态与建议**：

### 测试结果
1. **LD_LIBRARY_PATH方案初步测试**：没有立即出现GLIBCXX错误，服务器可能在初始化
2. **需要进一步测试**：需要更长运行时间确认方案是否有效

### 推荐行动方案

#### 方案A：继续测试LD_LIBRARY_PATH方案（推荐首先尝试）
```bash
# 清理环境
pkill -f "minisgl" 2>/dev/null || true
sleep 2

# 设置环境变量并运行
export LD_LIBRARY_PATH="/usr/lib/x86_64-linux-gnu:$LD_LIBRARY_PATH"
source .venv/bin/activate

# 运行30-60秒测试
timeout 45 python -m minisgl \
  --model-path "/home/kason/.cache/modelscope/hub/models/Qwen/Qwen3-0.6B" \
  --max-running-requests 1 \
  --port 1920 \
  --attention-backend fa
```

#### 方案B：更新Anaconda的libstdcxx-ng
```bash
# 检查当前版本
conda list libstdcxx-ng

# 更新到最新版本
conda update libstdcxx-ng

# 或者从conda-forge安装更新版本
conda install -c conda-forge libstdcxx-ng=12
```

#### 方案C：使用Docker（最可靠）
```bash
# 构建Docker镜像（首次需要时间）
docker build -t minisgl .

# 运行容器
docker run --gpus all -p 1919:1919 \
  minisgl --model Qwen/Qwen3-0.6B --host 0.0.0.0
```

#### 方案D：创建系统Python虚拟环境
```bash
# 使用系统Python（/usr/bin/python3）
/usr/bin/python3 -m venv .venv-system
source .venv-system/bin/activate
uv pip install -e .
```

### 决策建议
1. **如果您想快速看到mini-sGLang运行**：选择方案C（Docker）
2. **如果您希望修复当前开发环境**：选择方案B（更新Anaconda）
3. **如果您想先尝试最简单的修复**：选择方案A（LD_LIBRARY_PATH）
4. **如果您经常使用mini-sGLang**：选择方案D（系统Python虚拟环境）

### 学习计划调整
由于GLIBCXX问题，任务1.2可能需要额外时间。建议：
1. 先解决环境问题
2. 然后继续阶段一的其他任务
3. 将问题解决过程作为学习经验

### 下一步计划
1. 使用FlashAttention后端启动服务器
2. 测试API端点
3. 观察多进程架构
4. 分析日志输出

### 预计时间
- 实际用时：约1小时（等待安装）
- 预计总用时：2-3小时

### 参考资料
- [README.md](../README.md) - 项目文档
- [pyproject.toml](../pyproject.toml) - 项目配置
- [Dockerfile](../Dockerfile) - Docker配置

---
## 问题解决更新（2026-02-12 14:45）

### 成功解决GLIBCXX版本问题
**采用的方案**：方案D - 创建系统Python虚拟环境

#### 实施过程：
1. **创建新虚拟环境**：
   ```bash
   uv venv --python /usr/bin/python3 .venv-system
   ```

2. **安装依赖**：
   ```bash
   source .venv-system/bin/activate
   uv pip install -e .
   ```
   - 安装成功：77个包，419毫秒完成
   - 关键包：torch==2.9.1, flashinfer-python==0.5.3, minisgl==0.1.0

3. **环境验证**：
   ```bash
   python test_env.py
   ```
   - ✅ Python 3.12.3 (系统版本)
   - ✅ CUDA可用，PyTorch 2.9.1
   - ✅ minisgl模块导入成功

4. **服务器成功启动**：
   ```bash
   source .venv-system/bin/activate
   LOG_LEVEL=INFO python -m minisgl \
     --model-path "/home/kason/.cache/modelscope/hub/models/Qwen/Qwen3-0.6B" \
     --max-running-requests 1 \
     --port 1923 \
     --attention-backend fa
   ```
   - ✅ 服务器正常启动，无GLIBCXX错误
   - ✅ 使用FlashAttention后端
   - ✅ 使用本地模型路径

#### 根本原因确认：
- **问题根源**：Anaconda的libstdc++.so.6版本（6.0.29）缺少GLIBCXX_3.4.31和GLIBCXX_3.4.32符号
- **系统版本**：/usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.33 支持GLIBCXX_3.4.33
- **解决方案有效性**：使用系统Python创建的虚拟环境正确链接到系统libstdc++库

#### 关键学习点：
1. **环境隔离的重要性**：虚拟环境可以有效解决库版本冲突
2. **系统库的版本管理**：深度学习框架对系统库版本敏感
3. **问题诊断技巧**：通过错误信息精确定位库版本问题
4. **多方案准备**：准备多个解决方案（A/B/C/D）应对不同情况

#### 下一步行动：
1. 继续阶段一的其他任务（任务1.3-1.6）
2. 测试API端点功能
3. 分析多进程架构
4. 观察请求处理流程

---
*更新记录：2026-02-12 14:45*
*状态：GLIBCXX问题已解决，服务器成功启动*