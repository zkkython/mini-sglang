# 2.4 引擎初始化分析

> 源文件：`python/minisgl/engine/engine.py`

## 概览

Engine 是 mini-sGLang 的计算核心，负责模型加载、KV缓存分配、注意力后端初始化和 CUDA 图捕获。其 `__init__` 方法是整个系统最关键的初始化流程。

---

## 1. 初始化流程总览

```
Engine.__init__(config)
    │
    ├─ 1. 设置 TP 信息和 CUDA 设备
    ├─ 2. 初始化分布式通信 (Gloo/NCCL)
    ├─ 3. 记录初始空闲显存
    ├─ 4. 加载模型权重 (meta device → real device)
    ├─ 5. 计算可分配的 KV cache 页数
    ├─ 6. 创建 KV cache 张量
    ├─ 7. 创建 page_table
    ├─ 8. 初始化注意力后端 (FA/FI)
    ├─ 9. 初始化 MoE 后端 (可选)
    ├─ 10. 设置全局 Context
    ├─ 11. 创建 Sampler
    └─ 12. 捕获 CUDA 图 (GraphRunner)
```

---

## 2. 模型加载：Meta Device 技巧

```python
# 先在 meta device 上创建模型（不分配实际显存）
with torch.device("meta"), torch_dtype(config.dtype):
    self.model = create_model(config.model_config)

# 再加载实际权重
self.model.load_state_dict(self._load_weight_state_dict(config))
```

这种两步加载的好处：
- `meta` device 只创建张量的元信息（shape, dtype），不分配显存
- 避免了"先随机初始化再覆盖"的显存浪费
- 支持 `use_dummy_weight` 模式（用随机权重测试）

### 权重加载

```python
def _load_weight_state_dict(self, config):
    if config.use_dummy_weight:
        return {k: torch.randn_like(v, device=self.device) for k, v in ...}
    else:
        return {k: v.to(self.dtype) for k, v in load_hf_weight(config.model_path, self.device).items()}
```

---

## 3. KV Cache 页数计算

```python
def _determine_num_pages(self, old_free_memory, config):
    new_free_memory = self._sync_get_memory()[1]

    # 每页的显存开销
    cache_per_page = (
        2                          # K + V
        * head_dim
        * (num_kv_heads / tp_size) # TP 分片
        * page_size
        * dtype.itemsize           # 字节数
        * num_layers               # 所有层
    )

    # 可用显存 = 总显存 × memory_ratio - 模型占用
    model_memory = old_free_memory - new_free_memory
    available_memory = int(config.memory_ratio * old_free_memory) - model_memory
    num_pages = available_memory // cache_per_page
```

关键公式：
```
可用页数 = (总显存 × memory_ratio - 模型显存) / 每页显存
```

`memory_ratio` 默认 0.88，预留 12% 给 CUDA 图和临时张量。

---

## 4. 分布式通信初始化

```python
def _init_communication(self, config):
    if config.tp_info.size == 1 or config.use_pynccl:
        # 方案A: Gloo + PyNCCL
        torch.distributed.init_process_group(backend="gloo", ...)
        enable_pynccl_distributed(config.tp_info, tp_cpu_group, max_bytes)
    else:
        # 方案B: 原生 NCCL + Gloo (CPU通信)
        torch.distributed.init_process_group(backend="nccl", ...)
        tp_cpu_group = torch.distributed.new_group(backend="gloo")
```

两种方案：
- **Gloo + PyNCCL**：默认方案，PyNCCL 提供更灵活的 GPU 通信控制
- **原生 NCCL**：传统方案，使用 PyTorch 内置的 NCCL 后端

### 显存同步

```python
def _sync_get_memory(self):
    # 跨 TP rank 同步显存信息，取最小值
    # 如果 rank 间显存差异 > 2GB，报错
```

这确保了多 GPU 场景下 KV cache 分配的一致性。

---

## 5. 关键组件创建顺序

```
模型加载 → 计算页数 → KV cache → page_table → 注意力后端 → Context → Sampler → CUDA图
```

顺序很重要：
1. 先加载模型，才能知道模型占了多少显存
2. 知道剩余显存，才能计算 KV cache 页数
3. 有了 KV cache 和 page_table，才能初始化注意力后端
4. 注意力后端就绪后，才能设置全局 Context
5. 最后捕获 CUDA 图（需要所有组件就绪）

---

## 6. Page Table 设计

```python
self.max_seq_len = _align_up_32(min(config.max_seq_len, self.num_pages))
self.page_table = create_page_table(
    (config.max_running_req + 1, self.max_seq_len),  # +1 for dummy request
    device=self.device,
)
```

- 形状：`[max_running_req + 1, max_seq_len]`
- 每行对应一个请求（`table_idx`），每列对应一个 token 位置
- 值是 KV cache 中的页面索引
- `_align_up_32`：对齐到 32 的倍数（32 × 4 bytes = 128 bytes，缓存行对齐）
- 额外的 +1 行给 `dummy_req`（CUDA 图填充用）

---

## 7. forward_batch - 推理入口

```python
def forward_batch(self, batch: Batch, args: BatchSamplingArgs) -> ForwardOutput:
    with self.ctx.forward_batch(batch):          # 设置当前 batch 到全局 Context
        if self.graph_runner.can_use_cuda_graph(batch):
            logits = self.graph_runner.replay(batch)   # CUDA 图回放
        else:
            logits = self.model.forward()              # 正常前向传播

    for req in batch.reqs:
        req.complete_one()                       # 更新 cached_len 和 device_len

    next_tokens_gpu = self.sampler.sample(logits[:batch.size], args)
    next_tokens_cpu = next_tokens_gpu.to("cpu", non_blocking=True)
    copy_done_event = torch.cuda.Event()
    copy_done_event.record(self.stream)
    return ForwardOutput(next_tokens_gpu, next_tokens_cpu, copy_done_event)
```

异步拷贝设计：
- `non_blocking=True` — GPU→CPU 拷贝不阻塞 GPU
- `Event.record()` — 记录拷贝完成事件
- 调度器在 `_process_last_data` 中 `copy_done.synchronize()` 等待

---

## 关键设计总结

| 设计 | 说明 |
|------|------|
| Meta Device | 两步加载避免显存浪费 |
| 动态页数计算 | 根据实际剩余显存自动决定 KV cache 大小 |
| 128字节对齐 | page_table 列数对齐到 32（int32 × 32 = 128B） |
| 异步 GPU→CPU | Event 机制实现非阻塞结果传输 |
| Dummy Request | CUDA 图需要固定 batch size，用 dummy 填充 |
