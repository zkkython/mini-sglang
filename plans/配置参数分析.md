# Mini-SGLang 配置参数分析

## 概述
本文档详细分析mini-sGLang的配置参数，包括参数含义、默认值、影响范围和实验验证结果。参数解析实现在`python/minisgl/server/args.py`中。

## 参数分类

### 1. 模型与权重相关
| 参数 | 类型 | 默认值 | 说明 | 影响范围 |
|------|------|--------|------|----------|
| `--model-path` | string | **必填** | 模型权重路径，可以是本地文件夹或Hugging Face仓库ID | 模型加载、分词器初始化 |
| `--dtype` | enum | `"auto"` | 模型权重和激活的数据类型，`auto`自动选择：FP32/FP16模型用FP16，BF16模型用BF16 | GPU内存使用、计算精度、性能 |
| `--dummy-weight` | flag | `False` | 使用虚拟权重进行测试（不加载实际模型） | 测试和调试 |

### 2. 并行与分布式
| 参数 | 类型 | 默认值 | 说明 | 影响范围 |
|------|------|--------|------|----------|
| `--tensor-parallel-size` (`--tp-size`) | int | `1` | Tensor Parallelism大小，即使用的GPU数量 | Scheduler Workers数量、GPU间通信 |
| `--disable-pynccl` | flag | `False` | 禁用PyNCCL进行Tensor Parallelism通信 | 分布式通信性能、兼容性 |

### 3. 请求与调度
| 参数 | 类型 | 默认值 | 说明 | 影响范围 |
|------|------|--------|------|----------|
| `--max-running-requests` | int | `256` | 最大并发请求数 | 内存分配、调度队列大小 |
| `--max-seq-len-override` | int | `None` | 最大序列长度覆盖值 | KV缓存大小、长上下文支持 |
| `--memory-ratio` | float | `0.9` | 用于KV缓存的GPU内存比例（0.0-1.0） | KV缓存容量、并发请求数 |
| `--max-prefill-length` (`--max-extend-length`) | int | `8192` | Chunked Prefill的最大chunk大小（token数） | 预填充性能、内存峰值 |

### 4. 服务器网络
| 参数 | 类型 | 默认值 | 说明 | 影响范围 |
|------|------|--------|------|----------|
| `--host` | string | `"127.0.0.1"` | 服务器监听主机地址 | 网络可达性、安全 |
| `--port` | int | `1919` | 服务器监听端口号 | 客户端连接、端口冲突 |
| `--shell-mode` | flag | `False` | 运行shell交互模式，启用时自动设置`cuda_graph_max_bs=1`和`max_running_req=1` | 交互式使用、调试 |

### 5. Tokenizer处理
| 参数 | 类型 | 默认值 | 说明 | 影响范围 |
|------|------|--------|------|----------|
| `--num-tokenizer` (`--tokenizer-count`) | int | `0` | 启动的tokenizer进程数，`0`表示与detokenizer共享 | 分词吞吐量、进程数量 |

### 6. 性能优化
| 参数 | 类型 | 默认值 | 说明 | 影响范围 |
|------|------|--------|------|----------|
| `--cuda-graph-max-bs` (`--graph`) | int | `None` | CUDA图捕获的最大批处理大小，`None`表示基于GPU内存自动调整 | 推理延迟、GPU利用率 |
| `--attention-backend` (`--attn`) | enum | `"auto"` | 注意力后端，可选：`fa`(FlashAttention)、`fi`(FlashInfer)、`auto`自动选择 | 注意力计算性能、内存使用 |
| `--cache-type` | enum | `"radix"` | KV缓存管理策略：`naive`(简单分配)、`radix`(基数树共享前缀) | 缓存利用率、内存效率 |
| `--moe-backend` | enum | `"auto"` | MoE后端选择：`auto`、`fused` | MoE专家路由性能 |

### 7. 高级调试
| 参数 | 类型 | 默认值 | 说明 | 影响范围 |
|------|------|--------|------|----------|
| `--num-pages` (`--num-tokens`) | int | `None` | 设置KV缓存的最大页数，覆盖自动计算值 | 内存分配、调试 |

## 关键参数详解

### 1. `--memory-ratio` (默认: 0.9)
**作用**：控制分配给KV缓存的GPU内存比例。

**计算示例**：
```python
# 引擎初始化时计算（engine.py:48）
total_gpu_memory = torch.cuda.get_device_properties(0).total_memory
kv_cache_memory = total_gpu_memory * memory_ratio
```

**影响**：
- 值越高 → KV缓存容量越大 → 支持更长序列/更多并发
- 值越低 → 留给模型权重和激活的内存越多 → 可能减少OOM风险

**推荐范围**：0.5-0.9，取决于模型大小和序列长度需求。

### 2. `--max-running-requests` (默认: 256)
**作用**：限制系统中同时处理的请求数量。

**实现**：
```python
# scheduler.py中管理请求队列
self.running_reqs: Dict[int, Req]  # 运行中请求字典
self.waiting_reqs: List[Req]       # 等待队列
```

**影响**：
- 限制并发，防止内存溢出
- 影响系统吞吐量和延迟
- 过小值可能导致请求排队

### 3. `--max-prefill-length` (默认: 8192)
**作用**：控制Chunked Prefill的块大小。

**Chunked Prefill优势**：
1. 将长序列分成多个chunk处理
2. 减少峰值内存使用
3. 支持超长上下文推理

**调优建议**：
- 短序列（<4K）：可设置为4096或8192
- 长序列（>16K）：建议设置为1024或2048

### 4. `--cache-type` (默认: "radix")
**策略对比**：
| 策略 | 优点 | 缺点 | 适用场景 |
|------|------|------|----------|
| `naive` | 简单、低开销 | 缓存利用率低、不共享前缀 | 调试、简单测试 |
| `radix` | 共享前缀、高缓存利用率 | 实现复杂、管理开销 | 生产环境、多轮对话 |

### 5. `--attention-backend` (默认: "auto")
**后端选择逻辑**：
```python
# attention/__init__.py
if backend == "auto":
    if has_flashinfer and supports_tensor_core:
        return "fi"  # FlashInfer优先
    else:
        return "fa"  # FlashAttention回退
```

**性能特征**：
- **FlashInfer (fi)**：优化张量核心使用，A100/H100等高性能GPU
- **FlashAttention (fa)**：通用性好，支持多种GPU架构

## 参数依赖关系

### 1. 端口分配
```
服务器端口 (--port) = N
分布式通信端口 = N + 1  # 自动分配
ZMQ IPC地址 = ipc:///tmp/minisgl_* + 后缀
```

**冲突处理**：端口`N+1`必须可用，否则启动失败。

### 2. Shell模式自动调整
```python
# args.py:217-220
if run_shell:
    kwargs["cuda_graph_max_bs"] = 1      # 小批量适合交互
    kwargs["max_running_req"] = 1        # 单请求
    kwargs["silent_output"] = True       # 静默输出
```

### 3. Tokenizer共享
```python
# ServerArgs.zmq_tokenizer_addr属性
if self.share_tokenizer:  # num_tokenizer == 0
    return self.zmq_detokenizer_addr    # 共享地址
else:
    return "ipc:///tmp/minisgl_4" + self._unique_suffix  # 独立地址
```

## 实验验证结果

### 测试环境
- **模型**: Qwen/Qwen3-0.6B
- **GPU**: NVIDIA GPU (显存待确认)
- **Python环境**: .venv-system (系统Python 3.12)

### 测试1: 基础配置 (`--port 1929`)
**参数**：
```python
max_running_req=256
memory_ratio=0.9
max_extend_tokens=8192
cache_type='radix'
attention_backend='fa'
```

**结果**：
- ✅ 服务器启动成功
- ✅ CUDA图自动捕获（1-160 batch size）
- ✅ KV缓存分配：8.91 GiB (83462 pages)
- ❌ API测试需要设置`stream: false`

### 测试2: 限制并发 (`--max-running-requests 2`)
**参数变化**：`max_running_req=2`

**结果**：
- ✅ 参数生效（日志确认）
- ✅ 服务器正常启动
- ✅ 其他参数保持默认

**日志关键信息**：
```
max_running_req=2  # 确认参数生效
Allocating 83462 pages for KV cache, K + V = 8.91 GiB
Free memory after initialization: 1.15 GiB
```

### 测试3: 端口冲突 (`--port 1919`)
**问题**：端口1920（1919+1）被占用

**错误信息**：
```
torch.distributed.DistNetworkError: address already in use, port: 1920
```

**解决方案**：
1. 清理占用进程
2. 使用其他端口
3. 检查端口占用：`ss -tlnp | grep :1920`

## 参数调优建议

### 1. 生产环境配置
```bash
python -m minisgl \
  --model-path "Qwen/Qwen3-7B" \
  --memory-ratio 0.8 \
  --max-running-requests 128 \
  --max-prefill-length 4096 \
  --attention-backend fi \
  --cache-type radix \
  --port 8080
```

### 2. 调试配置
```bash
python -m minisgl \
  --model-path "Qwen/Qwen3-0.6B" \
  --max-running-requests 4 \
  --memory-ratio 0.5 \
  --cache-type naive \
  --dummy-weight  # 快速启动测试
```

### 3. 交互式使用
```bash
python -m minisgl \
  --model-path "Qwen/Qwen3-0.6B" \
  --shell-mode  # 自动优化交互体验
```

## 常见问题与解决方案

### 1. 端口冲突
**症状**：`EADDRINUSE: address already in use`

**原因**：
1. 服务器端口被占用
2. 分布式通信端口（server_port + 1）被占用

**解决**：
```bash
# 检查占用
ss -tlnp | grep :<端口号>

# 清理占用
kill $(lsof -ti:<端口号>)

# 使用不同端口
python -m minisgl --port 8080  # 自动使用8081作为分布式端口
```

### 2. 内存不足
**症状**：`CUDA out of memory`

**调整**：
1. 降低`--memory-ratio` (如0.5 → 0.3)
2. 减少`--max-running-requests`
3. 使用更小模型
4. 启用`--dummy-weight`测试内存分配

### 3. 启动缓慢
**原因**：
- 首次运行需要下载模型
- CUDA图捕获耗时

**优化**：
1. 使用本地模型路径
2. 调整`--cuda-graph-max-bs`限制捕获范围
3. 预热后性能稳定

## 性能指标监控

### 1. 启动阶段指标
```python
# 从日志中提取
Free memory before loading model: 11.50 GiB      # 加载前可用显存
Allocating 83462 pages for KV cache: 8.91 GiB   # KV缓存分配
Free memory after initialization: 1.15 GiB      # 初始化后可用显存
Free GPU memory after capturing CUDA graphs: 0.80 GiB  # CUDA图后显存
```

### 2. 运行时指标
- **Token生成速度**：tokens/秒
- **GPU利用率**：`nvidia-smi`监控
- **内存使用**：KV缓存 vs 模型权重

### 3. 配置影响评估
| 参数 | 延迟影响 | 吞吐量影响 | 内存影响 |
|------|----------|------------|----------|
| `--memory-ratio` | 低 | 高（更多并发） | 直接决定 |
| `--max-running-requests` | 高（排队） | 高（并发限制） | 间接影响 |
| `--attention-backend` | 中 | 中 | 低 |
| `--cache-type` | 低 | 中（缓存命中） | 高 |

## 学习收获

### 1. 参数设计理念
- **正交性**：各参数控制独立方面，减少耦合
- **自动化**：`auto`选项简化配置
- **安全性**：合理默认值防止误用

### 2. 性能调优方法
- **渐进式调整**：从一个稳定配置开始，逐步调整
- **监控驱动**：基于实际指标调整参数
- **场景适配**：生产、调试、交互不同配置

### 3. 问题诊断技能
- 通过日志理解参数生效情况
- 识别端口冲突等常见问题
- 利用默认值和自动调整机制

## 下一步实验建议

### 1. 深入性能测试
- 不同`--memory-ratio`下的并发能力
- `--cache-type`对多轮对话的影响
- 注意力后端性能对比

### 2. 边界条件测试
- 最小/最大参数值测试
- 长时间运行稳定性
- 高并发压力测试

### 3. 实际应用场景
- 集成到实际服务中的配置优化
- 多模型多服务部署
- 自动化配置管理

---
*分析时间: 2026-02-12*
*分析者: Claude Code 学习助手*