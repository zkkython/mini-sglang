# 3.4 KV 缓存管理分析

> 源文件：`python/minisgl/kvcache/`

## 概览

KV 缓存系统分为两层：

```
上层: CacheManager (scheduler/cache.py)
      → 页面分配/释放、驱逐决策、前缀匹配入口

下层: BaseCacheManager (kvcache/)
      → NaiveCacheManager: 无缓存复用
      → RadixCacheManager: Radix Tree 前缀共享

底层: MHAKVCache (kvcache/mha_pool.py)
      → 实际的 GPU 显存张量 (K/V buffer)
```

---

## 1. MHAKVCache - 实际显存分配

```python
class MHAKVCache(BaseKVCache):
    def __init__(self, num_kv_heads, num_layers, head_dim, num_pages, dtype, kv_layout, device):
        local_kv_heads = num_kv_heads // tp_size

        # 两种布局
        match kv_layout:
            case LayerFirst:   # [2, num_layers, num_pages, kv_heads, head_dim]
                kv_buffer = torch.empty(2, num_layers, num_pages, local_kv_heads, head_dim, ...)
            case PageFirst:    # [2, num_pages, num_layers, kv_heads, head_dim] → permute
                kv_buffer = torch.empty(2, num_pages, num_layers, ...).permute(0,2,1,3,4)

        self._kv_buffer = kv_buffer.view(2, num_layers, num_pages, 1, local_kv_heads, head_dim)
        self._k_buffer = self._kv_buffer[0]   # [num_layers, num_pages, 1, kv_heads, head_dim]
        self._v_buffer = self._kv_buffer[1]
```

### Layout 对比

```
LayerFirst: [2, L, P, H, D]  → 同一层的所有页面连续 → 层内访问友好
PageFirst:  [2, P, L, H, D]  → 同一页面的所有层连续 → 页面级操作友好
```

默认使用 `LayerFirst`，因为注意力计算是按层进行的。

### store_kv() - KV 写入

```python
def store_kv(self, k, v, out_loc, layer_id):
    from minisgl.kernel import store_cache
    store_cache(
        k_cache=self._k_buffer[layer_id].view(num_pages, -1),
        v_cache=self._v_buffer[layer_id].view(num_pages, -1),
        indices=out_loc,     # 要写入的页面索引
        k=k, v=v,
    )
```

使用 JIT 编译的 CUDA 内核 `store_cache` 进行散列写入。

---

## 2. NaiveCacheManager - 无缓存复用

```python
class NaiveCacheManager(BaseCacheManager):
    def match_prefix(self, input_ids):
        return NaiveCacheHandle(0), empty_tensor   # 永远不匹配，cached_len=0

    def lock_handle(self, handle, unlock=False):
        pass                                        # 无锁操作

    def insert_prefix(self, input_ids, indices):
        return len(indices)                         # 不插入，直接返回全部长度

    def evict(self, size):
        if size == 0: return empty_tensor
        raise NotImplementedError                   # 不支持驱逐

    @property
    def size_info(self):
        return SizeInfo(evictable_size=0, protected_size=0)  # 无缓存内容
```

NaiveCacheManager 是一个"空壳"实现：
- 每个请求都从头计算（`cached_len=0`）
- 不存储任何完成请求的 KV cache
- 适合简单场景或调试

---

## 3. RadixCacheManager - 前缀共享（核心）

### RadixTreeNode - 树节点

```python
class RadixTreeNode:
    children: Dict[int, RadixTreeNode]   # token_id → 子节点
    _parent: RadixTreeNode | None
    ref_count: int                        # 引用计数（0=可驱逐）
    timestamp: int                        # 最近访问时间戳
    _key: torch.Tensor                    # 该节点存储的 token 序列
    _value: torch.Tensor                  # 对应的页面索引
    _length: int                          # key 的长度
```

### Radix Tree 结构示例

假设有三个请求共享前缀：
```
请求1: "The cat sat on"       → tokens: [1, 2, 3, 4]
请求2: "The cat sat on the"   → tokens: [1, 2, 3, 4, 5]
请求3: "The dog ran"          → tokens: [1, 6, 7]

Radix Tree:
root
├── [1] "The"
│   ├── [2, 3, 4] "cat sat on"        ref=0, pages=[p0, p1, p2]
│   │   └── [5] "the"                 ref=0, pages=[p3]
│   └── [6, 7] "dog ran"              ref=0, pages=[p4, p5]
```

### match_prefix() - 前缀匹配

```python
def match_prefix(self, input_ids):
    node, prefix_len = self._walk(input_ids)
    # 收集从匹配节点到根的所有 value（页面索引）
    value_list = []
    while not node.is_root():
        value_list.append(node.value)
        node = node.parent
    value_list.reverse()
    return RadixCacheHandle(prefix_len, matched_node), torch.cat(value_list)
```

### _walk() - 树遍历

```python
def _walk(self, input_ids):
    prefix_len = 0
    node = self.root_node
    while prefix_len < len(input_ids):
        this_id = int(input_ids[prefix_len].item())
        if this_id not in node.children:
            return node, prefix_len           # 无匹配子节点

        node = node.children[this_id]
        match_len = node.get_match_len(input_ids[prefix_len:])  # 内核加速比较
        prefix_len += match_len

        if match_len != node.length:          # 部分匹配
            node = node._split_at(match_len)  # 分裂节点
            return node, prefix_len

        node.timestamp = tic                  # 更新访问时间
    return node, prefix_len
```

### _split_at() - 节点分裂

当部分匹配时，需要将一个节点拆成两个：

```
分裂前:
parent → [A, B, C, D] node (ref=0, pages=[p0,p1,p2,p3])

匹配了 [A, B]，分裂后:
parent → [A, B] new_node (ref=0, pages=[p0,p1])
              → [C, D] node (ref=0, pages=[p2,p3])
```

```python
def _split_at(self, pos):
    new_node = RadixTreeNode(self.timestamp)
    new_node.set_key_value(self._key[:pos], self._value[:pos])
    new_node.set_parent(parent)
    new_node.ref_count = self.ref_count

    self.set_key_value(self._key[pos:], self._value[pos:])
    self.set_parent(new_node)
    return new_node
```

### insert_prefix() - 插入

```python
def insert_prefix(self, input_ids, indices):
    node, prefix_len = self._walk(input_ids)
    if prefix_len < len(input_ids):
        new_node = RadixTreeNode()
        new_node.set_key_value(input_ids[prefix_len:], indices[prefix_len:].clone())
        new_node.set_parent(node)
        self.evictable_size += new_node.length
    return prefix_len   # 已存在的前缀长度（这些页面可以释放）
```

### evict() - LRU 驱逐

```python
def evict(self, size):
    leave_nodes = self._collect_leave_nodes_for_evict()  # 收集 ref_count=0 的叶节点
    heapq.heapify(leave_nodes)                            # 按 timestamp 排序（LRU）

    while evicted_size < size:
        node = heapq.heappop(leave_nodes)                # 取最久未访问的叶节点
        evicted_indices.append(node.value)
        del parent.children[node._key[0]]                 # 从树中移除
        if parent.is_leaf() and parent.ref_count == 0:
            heapq.heappush(leave_nodes, parent)            # 父节点变叶子，可能继续驱逐
```

驱逐策略：LRU（Least Recently Used），从叶子节点开始，按时间戳从旧到新驱逐。

### lock/unlock - 引用计数

```python
def lock_handle(self, handle, unlock=False):
    node = handle.node
    if unlock:
        while not node.is_root():
            node.ref_count -= 1
            if node.ref_count == 0:
                evictable_size += node.length     # 变为可驱逐
                protected_size -= node.length
            node = node.parent
    else:
        while not node.is_root():
            if node.ref_count == 0:
                evictable_size -= node.length     # 从可驱逐变为受保护
                protected_size += node.length
            node.ref_count += 1
            node = node.parent
```

锁定/解锁沿路径上的所有祖先节点，确保正在使用的缓存不被驱逐。

---

## 4. SizeInfo - 缓存大小信息

```python
class SizeInfo(NamedTuple):
    evictable_size: int     # 可驱逐的页面数（ref_count=0）
    protected_size: int     # 受保护的页面数（ref_count>0）

    @property
    def total_size(self):
        return self.evictable_size + self.protected_size
```

CacheManager 的 `available_size` = `evictable_size + free_slots`。

---

## 5. 完整 KV 缓存流程

```
新请求到达
    │
    ▼ CacheManager.match_req(req)
    │   → RadixCacheManager.match_prefix(input_ids[:-1])
    │   → 返回 (handle, matched_indices)
    │
    ▼ CacheManager.lock(handle)           # 锁定，防止被驱逐
    │
    ▼ PrefillAdder: 复制 cached 部分到 page_table
    │
    ▼ CacheManager.allocate(extend_len)   # 为新 token 分配页面
    │   → 空闲不够时: RadixCacheManager.evict()
    │
    ▼ Engine: forward → store_kv()        # 写入 KV cache
    │
    ▼ ... decode 循环 ...
    │
    ▼ 请求完成
    │
    ▼ CacheManager.free_and_cache_finished_req()
        │
        ├─ RadixCacheManager.insert_prefix(input_ids, indices)  # 插入树
        ├─ 释放已在树中的页面（避免重复）
        └─ CacheManager.unlock(handle)                          # 解锁
```

---

## 关键设计总结

| 设计 | NaiveCache | RadixCache |
|------|-----------|-----------|
| 前缀复用 | 无 | Radix Tree 匹配 |
| 驱逐策略 | 不支持 | LRU（基于叶节点时间戳） |
| 引用计数 | 无 | 路径级 ref_count |
| 内存效率 | 低（每次重算） | 高（共享前缀只存一份） |
| 适用场景 | 简单/调试 | 生产环境 |
| 复杂度 | O(1) | O(prefix_len) |
