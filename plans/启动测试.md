# Mini-SGLang 启动测试指南

## 安装完成后需要测试的步骤

### 1. 环境验证
```bash
# 激活虚拟环境
source .venv/bin/activate

# 运行环境测试脚本
python test_env.py

# 检查minisgl模块
python -c "import minisgl; print('✅ minisgl导入成功')"
```

### 2. 简单启动测试
```bash
# 使用小模型测试（Qwen3-0.6B）
python -m minisgl --model "Qwen/Qwen3-0.6B" --log-level DEBUG

# 或者使用shell模式
python -m minisgl --model "Qwen/Qwen3-0.6B" --shell
```

### 3. API服务器测试
```bash
# 启动服务器（后台运行）
python -m minisgl --model "Qwen/Qwen3-0.6B" --port 1919 &

# 测试API端点
curl -X POST http://localhost:1919/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "Qwen/Qwen3-0.6B",
    "messages": [
      {"role": "user", "content": "Hello, how are you?"}
    ],
    "max_tokens": 50
  }'
```

### 4. 进程结构检查
```bash
# 查看运行的进程
ps aux | grep minisgl

# 查看进程树
pstree -p | grep minisgl
```

### 5. 日志分析
```bash
# 查看日志输出（如果重定向到文件）
tail -f minisgl.log

# 或者直接观察控制台输出
```

## 预期结果

### 成功标志
1. ✅ 服务器正常启动，无错误信息
2. ✅ 显示"Server is ready"或类似消息
3. ✅ 进程结构包含：
   - API Server进程
   - Scheduler Worker进程（每个GPU一个）
   - Tokenizer Worker进程
   - Detokenizer Worker进程
4. ✅ API请求返回正常响应
5. ✅ 日志显示请求处理流程

### 常见问题排查

#### 问题1：模型下载失败
```
Error: Could not find model "Qwen/Qwen3-0.6B"
```
**解决方案**：
- 检查网络连接
- 手动下载模型：`huggingface-cli download Qwen/Qwen3-0.6B`
- 使用本地模型路径

#### 问题2：CUDA内存不足
```
CUDA out of memory
```
**解决方案**：
- 使用更小的模型
- 减少batch size：`--max-batch-size 4`
- 清理GPU内存

#### 问题3：端口被占用
```
Address already in use
```
**解决方案**：
- 使用不同端口：`--port 2929`
- 关闭占用端口的进程

#### 问题4：依赖缺失
```
ModuleNotFoundError: No module named '...'
```
**解决方案**：
- 重新安装依赖：`uv pip install -e .`
- 检查虚拟环境是否激活

## 测试用例

### 测试1：简单对话
```bash
curl -X POST http://localhost:1919/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "Qwen/Qwen3-0.6B",
    "messages": [
      {"role": "user", "content": "What is the capital of France?"}
    ],
    "max_tokens": 20
  }'
```

### 测试2：流式响应
```bash
curl -X POST http://localhost:1919/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "Qwen/Qwen3-0.6B",
    "messages": [
      {"role": "user", "content": "Tell me a short story."}
    ],
    "max_tokens": 100,
    "stream": true
  }'
```

### 测试3：批量请求
```bash
# 使用Python脚本发送多个请求
python -c "
import requests
import json

url = 'http://localhost:1919/v1/chat/completions'
headers = {'Content-Type': 'application/json'}

for i in range(3):
    data = {
        'model': 'Qwen/Qwen3-0.6B',
        'messages': [
            {'role': 'user', 'content': f'Message {i}: What is {i} + {i}?'}
        ],
        'max_tokens': 10
    }
    response = requests.post(url, headers=headers, json=data)
    print(f'Request {i}: {response.status_code}')
"
```

## 性能监控

### GPU使用情况
```bash
# 实时监控GPU
watch -n 1 nvidia-smi

# 查看GPU内存使用
nvidia-smi --query-gpu=memory.used,memory.total --format=csv
```

### 进程资源使用
```bash
# 查看CPU和内存使用
top -p $(pgrep -f minisgl | tr '\n' ',' | sed 's/,$//')

# 或者使用htop
htop -p $(pgrep -f minisgl)
```

## 日志级别说明

- `--log-level DEBUG`: 最详细，用于调试
- `--log-level INFO`: 默认级别，显示重要信息
- `--log-level WARNING`: 只显示警告和错误
- `--log-level ERROR`: 只显示错误

## 下一步
完成启动测试后，可以：
1. 分析日志，理解请求处理流程
2. 观察多进程间的通信
3. 测试不同配置参数的影响
4. 进行性能基准测试